<?xml version="1.0" standalone="no"?><!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"><svg version="1.1" width="1200" height="778" onload="init(evt)" viewBox="0 0 1200 778" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:fg="http://github.com/jonhoo/inferno"><!--Flame graph stack visualization. See https://github.com/brendangregg/FlameGraph for latest version, and http://www.brendangregg.com/flamegraphs.html for examples.--><!--NOTES: --><defs><linearGradient id="background" y1="0" y2="1" x1="0" x2="0"><stop stop-color="#eeeeee" offset="5%"/><stop stop-color="#eeeeb0" offset="95%"/></linearGradient></defs><style type="text/css">
text { font-family:"Verdana"; font-size:12px; fill:rgb(0,0,0); }
#title { text-anchor:middle; font-size:17px; }
#matched { text-anchor:end; }
#search { text-anchor:end; opacity:0.1; cursor:pointer; }
#search:hover, #search.show { opacity:1; }
#subtitle { text-anchor:middle; font-color:rgb(160,160,160); }
#unzoom { cursor:pointer; }
#frames > *:hover { stroke:black; stroke-width:0.5; cursor:pointer; }
.hide { display:none; }
.parent { opacity:0.5; }
</style><script type="text/ecmascript"><![CDATA[
        var nametype = 'Function:';
        var fontsize = 12;
        var fontwidth = 0.59;
        var xpad = 10;
        var inverted = true;
        var searchcolor = 'rgb(230,0,230)';
        var fluiddrawing = true;
        var truncate_text_right = false;
    ]]><![CDATA["use strict";
var details, searchbtn, unzoombtn, matchedtxt, svg, searching, frames;
function init(evt) {
    details = document.getElementById("details").firstChild;
    searchbtn = document.getElementById("search");
    unzoombtn = document.getElementById("unzoom");
    matchedtxt = document.getElementById("matched");
    svg = document.getElementsByTagName("svg")[0];
    frames = document.getElementById("frames");
    total_samples = parseInt(frames.attributes.total_samples.value);
    searching = 0;

    // Use GET parameters to restore a flamegraph's state.
    var restore_state = function() {
        var params = get_params();
        if (params.x && params.y)
            zoom(find_group(document.querySelector('[*|x="' + params.x + '"][y="' + params.y + '"]')));
        if (params.s)
            search(params.s);
    };

    if (fluiddrawing) {
        // Make width dynamic so the SVG fits its parent's width.
        svg.removeAttribute("width");
        // Edge requires us to have a viewBox that gets updated with size changes.
        var isEdge = /Edge\/\d./i.test(navigator.userAgent);
        var update_for_width_change = function() {
            if (isEdge) {
                svg.attributes.viewBox.value = "0 0 " + svg.width.baseVal.value + " " + svg.height.baseVal.value;
            }

            // Keep consistent padding on left and right of frames container.
            frames.attributes.width.value = svg.width.baseVal.value - xpad * 2;

            // Text truncation needs to be adjusted for the current width.
            var el = frames.children;
            for(var i = 0; i < el.length; i++) {
                update_text(el[i]);
            }

            // Keep search elements at a fixed distance from right edge.
            var svgWidth = svg.width.baseVal.value;
            searchbtn.attributes.x.value = svgWidth - xpad;
            matchedtxt.attributes.x.value = svgWidth - xpad;
        };
        window.addEventListener('resize', function() {
            update_for_width_change();
        });
        // This needs to be done asynchronously for Safari to work.
        setTimeout(function() {
            unzoom();
            update_for_width_change();
            restore_state();
            if (!isEdge) {
                svg.removeAttribute("viewBox");
            }
        }, 0);
    } else {
        restore_state();
    }
}
// event listeners
window.addEventListener("click", function(e) {
    var target = find_group(e.target);
    if (target) {
        if (target.nodeName == "a") {
            if (e.ctrlKey === false) return;
            e.preventDefault();
        }
        if (target.classList.contains("parent")) unzoom();
        zoom(target);

        // set parameters for zoom state
        var el = target.querySelector("rect");
        if (el && el.attributes && el.attributes.y && el.attributes["fg:x"]) {
            var params = get_params()
            params.x = el.attributes["fg:x"].value;
            params.y = el.attributes.y.value;
            history.replaceState(null, null, parse_params(params));
        }
    }
    else if (e.target.id == "unzoom") {
        unzoom();

        // remove zoom state
        var params = get_params();
        if (params.x) delete params.x;
        if (params.y) delete params.y;
        history.replaceState(null, null, parse_params(params));
    }
    else if (e.target.id == "search") search_prompt();
}, false)
// mouse-over for info
// show
window.addEventListener("mouseover", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = nametype + " " + g_to_text(target);
}, false)
// clear
window.addEventListener("mouseout", function(e) {
    var target = find_group(e.target);
    if (target) details.nodeValue = ' ';
}, false)
// ctrl-F for search
window.addEventListener("keydown",function (e) {
    if (e.keyCode === 114 || (e.ctrlKey && e.keyCode === 70)) {
        e.preventDefault();
        search_prompt();
    }
}, false)
// functions
function get_params() {
    var params = {};
    var paramsarr = window.location.search.substr(1).split('&');
    for (var i = 0; i < paramsarr.length; ++i) {
        var tmp = paramsarr[i].split("=");
        if (!tmp[0] || !tmp[1]) continue;
        params[tmp[0]]  = decodeURIComponent(tmp[1]);
    }
    return params;
}
function parse_params(params) {
    var uri = "?";
    for (var key in params) {
        uri += key + '=' + encodeURIComponent(params[key]) + '&';
    }
    if (uri.slice(-1) == "&")
        uri = uri.substring(0, uri.length - 1);
    if (uri == '?')
        uri = window.location.href.split('?')[0];
    return uri;
}
function find_child(node, selector) {
    var children = node.querySelectorAll(selector);
    if (children.length) return children[0];
    return;
}
function find_group(node) {
    var parent = node.parentElement;
    if (!parent) return;
    if (parent.id == "frames") return node;
    return find_group(parent);
}
function orig_save(e, attr, val) {
    if (e.attributes["fg:orig_" + attr] != undefined) return;
    if (e.attributes[attr] == undefined) return;
    if (val == undefined) val = e.attributes[attr].value;
    e.setAttribute("fg:orig_" + attr, val);
}
function orig_load(e, attr) {
    if (e.attributes["fg:orig_"+attr] == undefined) return;
    e.attributes[attr].value = e.attributes["fg:orig_" + attr].value;
    e.removeAttribute("fg:orig_" + attr);
}
function g_to_text(e) {
    var text = find_child(e, "title").firstChild.nodeValue;
    return (text)
}
function g_to_func(e) {
    var func = g_to_text(e);
    // if there's any manipulation we want to do to the function
    // name before it's searched, do it here before returning.
    return (func);
}
function update_text(e) {
    var r = find_child(e, "rect");
    var t = find_child(e, "text");
    var w = parseFloat(r.attributes.width.value) * frames.attributes.width.value / 100 - 3;
    var txt = find_child(e, "title").textContent.replace(/\([^(]*\)$/,"");
    t.attributes.x.value = format_percent((parseFloat(r.attributes.x.value) + (100 * 3 / frames.attributes.width.value)));
    // Smaller than this size won't fit anything
    if (w < 2 * fontsize * fontwidth) {
        t.textContent = "";
        return;
    }
    t.textContent = txt;
    // Fit in full text width
    if (/^ *\$/.test(txt) || t.getComputedTextLength() < w)
        return;
    if (truncate_text_right) {
        // Truncate the right side of the text.
        for (var x = txt.length - 2; x > 0; x--) {
            if (t.getSubStringLength(0, x + 2) <= w) {
                t.textContent = txt.substring(0, x) + "..";
                return;
            }
        }
    } else {
        // Truncate the left side of the text.
        for (var x = 2; x < txt.length; x++) {
            if (t.getSubStringLength(x - 2, txt.length) <= w) {
                t.textContent = ".." + txt.substring(x, txt.length);
                return;
            }
        }
    }
    t.textContent = "";
}
// zoom
function zoom_reset(e) {
    if (e.tagName == "rect") {
        e.attributes.x.value = format_percent(100 * parseInt(e.attributes["fg:x"].value) / total_samples);
        e.attributes.width.value = format_percent(100 * parseInt(e.attributes["fg:w"].value) / total_samples);
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_reset(c[i]);
    }
}
function zoom_child(e, x, zoomed_width_samples) {
    if (e.tagName == "text") {
        var parent_x = parseFloat(find_child(e.parentNode, "rect[x]").attributes.x.value);
        e.attributes.x.value = format_percent(parent_x + (100 * 3 / frames.attributes.width.value));
    } else if (e.tagName == "rect") {
        e.attributes.x.value = format_percent(100 * (parseInt(e.attributes["fg:x"].value) - x) / zoomed_width_samples);
        e.attributes.width.value = format_percent(100 * parseInt(e.attributes["fg:w"].value) / zoomed_width_samples);
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_child(c[i], x, zoomed_width_samples);
    }
}
function zoom_parent(e) {
    if (e.attributes) {
        if (e.attributes.x != undefined) {
            e.attributes.x.value = "0.0%";
        }
        if (e.attributes.width != undefined) {
            e.attributes.width.value = "100.0%";
        }
    }
    if (e.childNodes == undefined) return;
    for(var i = 0, c = e.childNodes; i < c.length; i++) {
        zoom_parent(c[i]);
    }
}
function zoom(node) {
    var attr = find_child(node, "rect").attributes;
    var width = parseInt(attr["fg:w"].value);
    var xmin = parseInt(attr["fg:x"].value);
    var xmax = xmin + width;
    var ymin = parseFloat(attr.y.value);
    unzoombtn.classList.remove("hide");
    var el = frames.children;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        var a = find_child(e, "rect").attributes;
        var ex = parseInt(a["fg:x"].value);
        var ew = parseInt(a["fg:w"].value);
        // Is it an ancestor
        if (!inverted) {
            var upstack = parseFloat(a.y.value) > ymin;
        } else {
            var upstack = parseFloat(a.y.value) < ymin;
        }
        if (upstack) {
            // Direct ancestor
            if (ex <= xmin && (ex+ew) >= xmax) {
                e.classList.add("parent");
                zoom_parent(e);
                update_text(e);
            }
            // not in current path
            else
                e.classList.add("hide");
        }
        // Children maybe
        else {
            // no common path
            if (ex < xmin || ex >= xmax) {
                e.classList.add("hide");
            }
            else {
                zoom_child(e, xmin, width);
                update_text(e);
            }
        }
    }
}
function unzoom() {
    unzoombtn.classList.add("hide");
    var el = frames.children;
    for(var i = 0; i < el.length; i++) {
        el[i].classList.remove("parent");
        el[i].classList.remove("hide");
        zoom_reset(el[i]);
        update_text(el[i]);
    }
}
// search
function reset_search() {
    var el = document.querySelectorAll("#frames rect");
    for (var i = 0; i < el.length; i++) {
        orig_load(el[i], "fill")
    }
    var params = get_params();
    delete params.s;
    history.replaceState(null, null, parse_params(params));
}
function search_prompt() {
    if (!searching) {
        var term = prompt("Enter a search term (regexp " +
            "allowed, eg: ^ext4_)", "");
        if (term != null) {
            search(term)
        }
    } else {
        reset_search();
        searching = 0;
        searchbtn.classList.remove("show");
        searchbtn.firstChild.nodeValue = "Search"
        matchedtxt.classList.add("hide");
        matchedtxt.firstChild.nodeValue = ""
    }
}
function search(term) {
    var re = new RegExp(term);
    var el = frames.children;
    var matches = new Object();
    var maxwidth = 0;
    for (var i = 0; i < el.length; i++) {
        var e = el[i];
        // Skip over frames which are either not visible, or below the zoomed-to frame
        if (e.classList.contains("hide") || e.classList.contains("parent")) {
            continue;
        }
        var func = g_to_func(e);
        var rect = find_child(e, "rect");
        if (func == null || rect == null)
            continue;
        // Save max width. Only works as we have a root frame
        var w = parseInt(rect.attributes["fg:w"].value);
        if (w > maxwidth)
            maxwidth = w;
        if (func.match(re)) {
            // highlight
            var x = parseInt(rect.attributes["fg:x"].value);
            orig_save(rect, "fill");
            rect.attributes.fill.value = searchcolor;
            // remember matches
            if (matches[x] == undefined) {
                matches[x] = w;
            } else {
                if (w > matches[x]) {
                    // overwrite with parent
                    matches[x] = w;
                }
            }
            searching = 1;
        }
    }
    if (!searching)
        return;
    var params = get_params();
    params.s = term;
    history.replaceState(null, null, parse_params(params));

    searchbtn.classList.add("show");
    searchbtn.firstChild.nodeValue = "Reset Search";
    // calculate percent matched, excluding vertical overlap
    var count = 0;
    var lastx = -1;
    var lastw = 0;
    var keys = Array();
    for (k in matches) {
        if (matches.hasOwnProperty(k))
            keys.push(k);
    }
    // sort the matched frames by their x location
    // ascending, then width descending
    keys.sort(function(a, b){
        return a - b;
    });
    // Step through frames saving only the biggest bottom-up frames
    // thanks to the sort order. This relies on the tree property
    // where children are always smaller than their parents.
    for (var k in keys) {
        var x = parseInt(keys[k]);
        var w = matches[keys[k]];
        if (x >= lastx + lastw) {
            count += w;
            lastx = x;
            lastw = w;
        }
    }
    // display matched percent
    matchedtxt.classList.remove("hide");
    var pct = 100 * count / maxwidth;
    if (pct != 100) pct = pct.toFixed(1);
    matchedtxt.firstChild.nodeValue = "Matched: " + pct + "%";
}
function format_percent(n) {
    return n.toFixed(4) + "%";
}
]]></script><rect x="0" y="0" width="100%" height="778" fill="url(#background)"/><text id="title" x="50.0000%" y="24.00">py-spy record -o profile.svg --rate 1 -- python extraction_flame.py</text><text id="details" x="10" y="40.00"> </text><text id="unzoom" class="hide" x="10" y="24.00">Reset Zoom</text><text id="search" x="1190" y="24.00">Search</text><text id="matched" x="1190" y="767.00"> </text><svg id="frames" x="10" width="1180" total_samples="54"><g><title>learn (pdfa_quantization_n_ary_tree_learner.py:91) (1 samples, 1.85%)</title><rect x="0.0000%" y="148" width="1.8519%" height="15" fill="rgb(227,0,7)" fg:x="0" fg:w="1"/><text x="0.2500%" y="158.50">l..</text></g><g><title>initialization (bounded_pdfa_quantization_n_ary_tree_learner.py:71) (1 samples, 1.85%)</title><rect x="0.0000%" y="164" width="1.8519%" height="15" fill="rgb(217,0,24)" fg:x="0" fg:w="1"/><text x="0.2500%" y="174.50">i..</text></g><g><title>initialization (pdfa_quantization_n_ary_tree_learner.py:70) (1 samples, 1.85%)</title><rect x="0.0000%" y="180" width="1.8519%" height="15" fill="rgb(221,193,54)" fg:x="0" fg:w="1"/><text x="0.2500%" y="190.50">i..</text></g><g><title>_perform_next_token_probabilities (pdfa_quantization_n_ary_tree_learner.py:47) (1 samples, 1.85%)</title><rect x="0.0000%" y="196" width="1.8519%" height="15" fill="rgb(248,212,6)" fg:x="0" fg:w="1"/><text x="0.2500%" y="206.50">_..</text></g><g><title>next_token_probabilities (pymodelextractor/teachers/probabilistic_teacher.py:57) (1 samples, 1.85%)</title><rect x="0.0000%" y="212" width="1.8519%" height="15" fill="rgb(208,68,35)" fg:x="0" fg:w="1"/><text x="0.2500%" y="222.50">n..</text></g><g><title>last_token_weights (pymodelextractor/teachers/probabilistic_teacher.py:45) (1 samples, 1.85%)</title><rect x="0.0000%" y="228" width="1.8519%" height="15" fill="rgb(232,128,0)" fg:x="0" fg:w="1"/><text x="0.2500%" y="238.50">l..</text></g><g><title>get_last_token_weights (synchronic_model_guided_language_model.py:126) (1 samples, 1.85%)</title><rect x="0.0000%" y="244" width="1.8519%" height="15" fill="rgb(207,160,47)" fg:x="0" fg:w="1"/><text x="0.2500%" y="254.50">g..</text></g><g><title>_raw_last_token_weights (synchronic_model_guided_language_model.py:102) (1 samples, 1.85%)</title><rect x="0.0000%" y="260" width="1.8519%" height="15" fill="rgb(228,23,34)" fg:x="0" fg:w="1"/><text x="0.2500%" y="270.50">_..</text></g><g><title>get_last_token_weights (gpt2_probabilistic_model_wrapper.py:48) (1 samples, 1.85%)</title><rect x="0.0000%" y="276" width="1.8519%" height="15" fill="rgb(218,30,26)" fg:x="0" fg:w="1"/><text x="0.2500%" y="286.50">g..</text></g><g><title>last_token_probability (gpt2_probabilistic_model_wrapper.py:43) (1 samples, 1.85%)</title><rect x="0.0000%" y="292" width="1.8519%" height="15" fill="rgb(220,122,19)" fg:x="0" fg:w="1"/><text x="0.2500%" y="302.50">l..</text></g><g><title>_get_probability (gpt2_probabilistic_model_wrapper.py:91) (1 samples, 1.85%)</title><rect x="0.0000%" y="308" width="1.8519%" height="15" fill="rgb(250,228,42)" fg:x="0" fg:w="1"/><text x="0.2500%" y="318.50">_..</text></g><g><title>_get_symbols_probabilities_dict (gpt2_probabilistic_model_wrapper.py:113) (1 samples, 1.85%)</title><rect x="0.0000%" y="324" width="1.8519%" height="15" fill="rgb(240,193,28)" fg:x="0" fg:w="1"/><text x="0.2500%" y="334.50">_..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="0.0000%" y="340" width="1.8519%" height="15" fill="rgb(216,20,37)" fg:x="0" fg:w="1"/><text x="0.2500%" y="350.50">_..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1315) (1 samples, 1.85%)</title><rect x="0.0000%" y="356" width="1.8519%" height="15" fill="rgb(206,188,39)" fg:x="0" fg:w="1"/><text x="0.2500%" y="366.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="0.0000%" y="372" width="1.8519%" height="15" fill="rgb(217,207,13)" fg:x="0" fg:w="1"/><text x="0.2500%" y="382.50">_..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1129) (1 samples, 1.85%)</title><rect x="0.0000%" y="388" width="1.8519%" height="15" fill="rgb(231,73,38)" fg:x="0" fg:w="1"/><text x="0.2500%" y="398.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="0.0000%" y="404" width="1.8519%" height="15" fill="rgb(225,20,46)" fg:x="0" fg:w="1"/><text x="0.2500%" y="414.50">_..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:613) (1 samples, 1.85%)</title><rect x="0.0000%" y="420" width="1.8519%" height="15" fill="rgb(210,31,41)" fg:x="0" fg:w="1"/><text x="0.2500%" y="430.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="0.0000%" y="436" width="1.8519%" height="15" fill="rgb(221,200,47)" fg:x="0" fg:w="1"/><text x="0.2500%" y="446.50">_..</text></g><g><title>forward (torch/nn/modules/normalization.py:190) (1 samples, 1.85%)</title><rect x="0.0000%" y="452" width="1.8519%" height="15" fill="rgb(226,26,5)" fg:x="0" fg:w="1"/><text x="0.2500%" y="462.50">f..</text></g><g><title>__getattr__ (torch/nn/modules/module.py:1167) (1 samples, 1.85%)</title><rect x="0.0000%" y="468" width="1.8519%" height="15" fill="rgb(249,33,26)" fg:x="0" fg:w="1"/><text x="0.2500%" y="478.50">_..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:613) (1 samples, 1.85%)</title><rect x="1.8519%" y="388" width="1.8519%" height="15" fill="rgb(235,183,28)" fg:x="1" fg:w="1"/><text x="2.1019%" y="398.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="1.8519%" y="404" width="1.8519%" height="15" fill="rgb(221,5,38)" fg:x="1" fg:w="1"/><text x="2.1019%" y="414.50">_..</text></g><g><title>forward (torch/nn/modules/normalization.py:189) (1 samples, 1.85%)</title><rect x="1.8519%" y="420" width="1.8519%" height="15" fill="rgb(247,18,42)" fg:x="1" fg:w="1"/><text x="2.1019%" y="430.50">f..</text></g><g><title>layer_norm (torch/nn/functional.py:2347) (1 samples, 1.85%)</title><rect x="1.8519%" y="436" width="1.8519%" height="15" fill="rgb(241,131,45)" fg:x="1" fg:w="1"/><text x="2.1019%" y="446.50">l..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:312) (4 samples, 7.41%)</title><rect x="3.7037%" y="420" width="7.4074%" height="15" fill="rgb(249,31,29)" fg:x="2" fg:w="4"/><text x="3.9537%" y="430.50">forward (t..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (4 samples, 7.41%)</title><rect x="3.7037%" y="436" width="7.4074%" height="15" fill="rgb(225,111,53)" fg:x="2" fg:w="4"/><text x="3.9537%" y="446.50">_call_impl..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (4 samples, 7.41%)</title><rect x="3.7037%" y="452" width="7.4074%" height="15" fill="rgb(238,160,17)" fg:x="2" fg:w="4"/><text x="3.9537%" y="462.50">forward (t..</text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:183) (1 samples, 1.85%)</title><rect x="11.1111%" y="436" width="1.8519%" height="15" fill="rgb(214,148,48)" fg:x="6" fg:w="1"/><text x="11.3611%" y="446.50">_..</text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:208) (1 samples, 1.85%)</title><rect x="12.9630%" y="436" width="1.8519%" height="15" fill="rgb(232,36,49)" fg:x="7" fg:w="1"/><text x="13.2130%" y="446.50">_..</text></g><g><title>softmax (torch/nn/functional.py:1680) (1 samples, 1.85%)</title><rect x="12.9630%" y="452" width="1.8519%" height="15" fill="rgb(209,103,24)" fg:x="7" fg:w="1"/><text x="13.2130%" y="462.50">s..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:331) (4 samples, 7.41%)</title><rect x="11.1111%" y="420" width="7.4074%" height="15" fill="rgb(229,88,8)" fg:x="6" fg:w="4"/><text x="11.3611%" y="430.50">forward (t..</text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:218) (2 samples, 3.70%)</title><rect x="14.8148%" y="436" width="3.7037%" height="15" fill="rgb(213,181,19)" fg:x="8" fg:w="2"/><text x="15.0648%" y="446.50">_att..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:614) (11 samples, 20.37%)</title><rect x="3.7037%" y="388" width="20.3704%" height="15" fill="rgb(254,191,54)" fg:x="2" fg:w="11"/><text x="3.9537%" y="398.50">forward (transformers/models/gpt..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (11 samples, 20.37%)</title><rect x="3.7037%" y="404" width="20.3704%" height="15" fill="rgb(241,83,37)" fg:x="2" fg:w="11"/><text x="3.9537%" y="414.50">_call_impl (torch/nn/modules/mod..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:334) (3 samples, 5.56%)</title><rect x="18.5185%" y="420" width="5.5556%" height="15" fill="rgb(233,36,39)" fg:x="10" fg:w="3"/><text x="18.7685%" y="430.50">forward..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (3 samples, 5.56%)</title><rect x="18.5185%" y="436" width="5.5556%" height="15" fill="rgb(226,3,54)" fg:x="10" fg:w="3"/><text x="18.7685%" y="446.50">_call_i..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (3 samples, 5.56%)</title><rect x="18.5185%" y="452" width="5.5556%" height="15" fill="rgb(245,192,40)" fg:x="10" fg:w="3"/><text x="18.7685%" y="462.50">forward..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:574) (3 samples, 5.56%)</title><rect x="24.0741%" y="420" width="5.5556%" height="15" fill="rgb(238,167,29)" fg:x="13" fg:w="3"/><text x="24.3241%" y="430.50">forward..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (3 samples, 5.56%)</title><rect x="24.0741%" y="436" width="5.5556%" height="15" fill="rgb(232,182,51)" fg:x="13" fg:w="3"/><text x="24.3241%" y="446.50">_call_i..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (3 samples, 5.56%)</title><rect x="24.0741%" y="452" width="5.5556%" height="15" fill="rgb(231,60,39)" fg:x="13" fg:w="3"/><text x="24.3241%" y="462.50">forward..</text></g><g><title>_get_probability (gpt2_probabilistic_model_wrapper.py:87) (22 samples, 40.74%)</title><rect x="1.8519%" y="292" width="40.7407%" height="15" fill="rgb(208,69,12)" fg:x="1" fg:w="22"/><text x="2.1019%" y="302.50">_get_probability (gpt2_probabilistic_model_wrapper.py:87)</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (22 samples, 40.74%)</title><rect x="1.8519%" y="308" width="40.7407%" height="15" fill="rgb(235,93,37)" fg:x="1" fg:w="22"/><text x="2.1019%" y="318.50">_call_impl (torch/nn/modules/module.py:1102)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1315) (22 samples, 40.74%)</title><rect x="1.8519%" y="324" width="40.7407%" height="15" fill="rgb(213,116,39)" fg:x="1" fg:w="22"/><text x="2.1019%" y="334.50">forward (transformers/models/gpt2/modeling_gpt2.py:1315)</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (22 samples, 40.74%)</title><rect x="1.8519%" y="340" width="40.7407%" height="15" fill="rgb(222,207,29)" fg:x="1" fg:w="22"/><text x="2.1019%" y="350.50">_call_impl (torch/nn/modules/module.py:1102)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1129) (22 samples, 40.74%)</title><rect x="1.8519%" y="356" width="40.7407%" height="15" fill="rgb(206,96,30)" fg:x="1" fg:w="22"/><text x="2.1019%" y="366.50">forward (transformers/models/gpt2/modeling_gpt2.py:1129)</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (22 samples, 40.74%)</title><rect x="1.8519%" y="372" width="40.7407%" height="15" fill="rgb(218,138,4)" fg:x="1" fg:w="22"/><text x="2.1019%" y="382.50">_call_impl (torch/nn/modules/module.py:1102)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:651) (10 samples, 18.52%)</title><rect x="24.0741%" y="388" width="18.5185%" height="15" fill="rgb(250,191,14)" fg:x="13" fg:w="10"/><text x="24.3241%" y="398.50">forward (transformers/models/..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (10 samples, 18.52%)</title><rect x="24.0741%" y="404" width="18.5185%" height="15" fill="rgb(239,60,40)" fg:x="13" fg:w="10"/><text x="24.3241%" y="414.50">_call_impl (torch/nn/modules/..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:575) (7 samples, 12.96%)</title><rect x="29.6296%" y="420" width="12.9630%" height="15" fill="rgb(206,27,48)" fg:x="16" fg:w="7"/><text x="29.8796%" y="430.50">forward (transforme..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (7 samples, 12.96%)</title><rect x="29.6296%" y="436" width="12.9630%" height="15" fill="rgb(225,35,8)" fg:x="16" fg:w="7"/><text x="29.8796%" y="446.50">_call_impl (torch/n..</text></g><g><title>forward (transformers/activations.py:56) (7 samples, 12.96%)</title><rect x="29.6296%" y="452" width="12.9630%" height="15" fill="rgb(250,213,24)" fg:x="16" fg:w="7"/><text x="29.8796%" y="462.50">forward (transforme..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:613) (3 samples, 5.56%)</title><rect x="42.5926%" y="404" width="5.5556%" height="15" fill="rgb(247,123,22)" fg:x="23" fg:w="3"/><text x="42.8426%" y="414.50">forward..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (3 samples, 5.56%)</title><rect x="42.5926%" y="420" width="5.5556%" height="15" fill="rgb(231,138,38)" fg:x="23" fg:w="3"/><text x="42.8426%" y="430.50">_call_i..</text></g><g><title>forward (torch/nn/modules/normalization.py:189) (3 samples, 5.56%)</title><rect x="42.5926%" y="436" width="5.5556%" height="15" fill="rgb(231,145,46)" fg:x="23" fg:w="3"/><text x="42.8426%" y="446.50">forward..</text></g><g><title>layer_norm (torch/nn/functional.py:2347) (3 samples, 5.56%)</title><rect x="42.5926%" y="452" width="5.5556%" height="15" fill="rgb(251,118,11)" fg:x="23" fg:w="3"/><text x="42.8426%" y="462.50">layer_n..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:312) (1 samples, 1.85%)</title><rect x="48.1481%" y="436" width="1.8519%" height="15" fill="rgb(217,147,25)" fg:x="26" fg:w="1"/><text x="48.3981%" y="446.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="48.1481%" y="452" width="1.8519%" height="15" fill="rgb(247,81,37)" fg:x="26" fg:w="1"/><text x="48.3981%" y="462.50">_..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (1 samples, 1.85%)</title><rect x="48.1481%" y="468" width="1.8519%" height="15" fill="rgb(209,12,38)" fg:x="26" fg:w="1"/><text x="48.3981%" y="478.50">f..</text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:183) (1 samples, 1.85%)</title><rect x="50.0000%" y="452" width="1.8519%" height="15" fill="rgb(227,1,9)" fg:x="27" fg:w="1"/><text x="50.2500%" y="462.50">_..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:614) (5 samples, 9.26%)</title><rect x="48.1481%" y="404" width="9.2593%" height="15" fill="rgb(248,47,43)" fg:x="26" fg:w="5"/><text x="48.3981%" y="414.50">forward (tran..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (5 samples, 9.26%)</title><rect x="48.1481%" y="420" width="9.2593%" height="15" fill="rgb(221,10,30)" fg:x="26" fg:w="5"/><text x="48.3981%" y="430.50">_call_impl (t..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:331) (4 samples, 7.41%)</title><rect x="50.0000%" y="436" width="7.4074%" height="15" fill="rgb(210,229,1)" fg:x="27" fg:w="4"/><text x="50.2500%" y="446.50">forward (t..</text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:208) (3 samples, 5.56%)</title><rect x="51.8519%" y="452" width="5.5556%" height="15" fill="rgb(222,148,37)" fg:x="28" fg:w="3"/><text x="52.1019%" y="462.50">_attn (..</text></g><g><title>softmax (torch/nn/functional.py:1680) (3 samples, 5.56%)</title><rect x="51.8519%" y="468" width="5.5556%" height="15" fill="rgb(234,67,33)" fg:x="28" fg:w="3"/><text x="52.1019%" y="478.50">softmax..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:574) (2 samples, 3.70%)</title><rect x="57.4074%" y="436" width="3.7037%" height="15" fill="rgb(247,98,35)" fg:x="31" fg:w="2"/><text x="57.6574%" y="446.50">forw..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (2 samples, 3.70%)</title><rect x="57.4074%" y="452" width="3.7037%" height="15" fill="rgb(247,138,52)" fg:x="31" fg:w="2"/><text x="57.6574%" y="462.50">_cal..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (2 samples, 3.70%)</title><rect x="57.4074%" y="468" width="3.7037%" height="15" fill="rgb(213,79,30)" fg:x="31" fg:w="2"/><text x="57.6574%" y="478.50">forw..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:575) (1 samples, 1.85%)</title><rect x="61.1111%" y="436" width="1.8519%" height="15" fill="rgb(246,177,23)" fg:x="33" fg:w="1"/><text x="61.3611%" y="446.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="61.1111%" y="452" width="1.8519%" height="15" fill="rgb(230,62,27)" fg:x="33" fg:w="1"/><text x="61.3611%" y="462.50">_..</text></g><g><title>forward (transformers/activations.py:56) (1 samples, 1.85%)</title><rect x="61.1111%" y="468" width="1.8519%" height="15" fill="rgb(216,154,8)" fg:x="33" fg:w="1"/><text x="61.3611%" y="478.50">f..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1129) (12 samples, 22.22%)</title><rect x="42.5926%" y="372" width="22.2222%" height="15" fill="rgb(244,35,45)" fg:x="23" fg:w="12"/><text x="42.8426%" y="382.50">forward (transformers/models/gpt2/m..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (12 samples, 22.22%)</title><rect x="42.5926%" y="388" width="22.2222%" height="15" fill="rgb(251,115,12)" fg:x="23" fg:w="12"/><text x="42.8426%" y="398.50">_call_impl (torch/nn/modules/module..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:651) (4 samples, 7.41%)</title><rect x="57.4074%" y="404" width="7.4074%" height="15" fill="rgb(240,54,50)" fg:x="31" fg:w="4"/><text x="57.6574%" y="414.50">forward (t..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (4 samples, 7.41%)</title><rect x="57.4074%" y="420" width="7.4074%" height="15" fill="rgb(233,84,52)" fg:x="31" fg:w="4"/><text x="57.6574%" y="430.50">_call_impl..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:576) (1 samples, 1.85%)</title><rect x="62.9630%" y="436" width="1.8519%" height="15" fill="rgb(207,117,47)" fg:x="34" fg:w="1"/><text x="63.2130%" y="446.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="62.9630%" y="452" width="1.8519%" height="15" fill="rgb(249,43,39)" fg:x="34" fg:w="1"/><text x="63.2130%" y="462.50">_..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (1 samples, 1.85%)</title><rect x="62.9630%" y="468" width="1.8519%" height="15" fill="rgb(209,38,44)" fg:x="34" fg:w="1"/><text x="63.2130%" y="478.50">f..</text></g><g><title>learn (bounded_pdfa_quantization_n_ary_tree_learner.py:48) (36 samples, 66.67%)</title><rect x="0.0000%" y="116" width="66.6667%" height="15" fill="rgb(236,212,23)" fg:x="0" fg:w="36"/><text x="0.2500%" y="126.50">learn (bounded_pdfa_quantization_n_ary_tree_learner.py:48)</text></g><g><title>run_learning_with_time_bound (bounded_pdfa_quantization_n_ary_tree_learner.py:40) (36 samples, 66.67%)</title><rect x="0.0000%" y="132" width="66.6667%" height="15" fill="rgb(242,79,21)" fg:x="0" fg:w="36"/><text x="0.2500%" y="142.50">run_learning_with_time_bound (bounded_pdfa_quantization_n_ary_tree_learner.py:40)</text></g><g><title>learn (pdfa_quantization_n_ary_tree_learner.py:99) (35 samples, 64.81%)</title><rect x="1.8519%" y="148" width="64.8148%" height="15" fill="rgb(211,96,35)" fg:x="1" fg:w="35"/><text x="2.1019%" y="158.50">learn (pdfa_quantization_n_ary_tree_learner.py:99)</text></g><g><title>tentative_hypothesis (pdfa_quantization_n_ary_tree_learner.py:151) (35 samples, 64.81%)</title><rect x="1.8519%" y="164" width="64.8148%" height="15" fill="rgb(253,215,40)" fg:x="1" fg:w="35"/><text x="2.1019%" y="174.50">tentative_hypothesis (pdfa_quantization_n_ary_tree_learner.py:151)</text></g><g><title>cache_queries_for_building_hipothesis (pdfa_quantization_n_ary_tree_learner.py:276) (35 samples, 64.81%)</title><rect x="1.8519%" y="180" width="64.8148%" height="15" fill="rgb(211,81,21)" fg:x="1" fg:w="35"/><text x="2.1019%" y="190.50">cache_queries_for_building_hipothesis (pdfa_quantization_n_ary_tree_learner.py:276)</text></g><g><title>next_token_probabilities_batch (pymodelextractor/teachers/probabilistic_teacher.py:106) (35 samples, 64.81%)</title><rect x="1.8519%" y="196" width="64.8148%" height="15" fill="rgb(208,190,38)" fg:x="1" fg:w="35"/><text x="2.1019%" y="206.50">next_token_probabilities_batch (pymodelextractor/teachers/probabilistic_teacher.py:106)</text></g><g><title>get_last_token_weights_batch (synchronic_model_guided_language_model.py:74) (35 samples, 64.81%)</title><rect x="1.8519%" y="212" width="64.8148%" height="15" fill="rgb(235,213,38)" fg:x="1" fg:w="35"/><text x="2.1019%" y="222.50">get_last_token_weights_batch (synchronic_model_guided_language_model.py:74)</text></g><g><title>get_last_token_weights (synchronic_model_guided_language_model.py:126) (35 samples, 64.81%)</title><rect x="1.8519%" y="228" width="64.8148%" height="15" fill="rgb(237,122,38)" fg:x="1" fg:w="35"/><text x="2.1019%" y="238.50">get_last_token_weights (synchronic_model_guided_language_model.py:126)</text></g><g><title>_raw_last_token_weights (synchronic_model_guided_language_model.py:102) (35 samples, 64.81%)</title><rect x="1.8519%" y="244" width="64.8148%" height="15" fill="rgb(244,218,35)" fg:x="1" fg:w="35"/><text x="2.1019%" y="254.50">_raw_last_token_weights (synchronic_model_guided_language_model.py:102)</text></g><g><title>get_last_token_weights (gpt2_probabilistic_model_wrapper.py:48) (35 samples, 64.81%)</title><rect x="1.8519%" y="260" width="64.8148%" height="15" fill="rgb(240,68,47)" fg:x="1" fg:w="35"/><text x="2.1019%" y="270.50">get_last_token_weights (gpt2_probabilistic_model_wrapper.py:48)</text></g><g><title>last_token_probability (gpt2_probabilistic_model_wrapper.py:43) (35 samples, 64.81%)</title><rect x="1.8519%" y="276" width="64.8148%" height="15" fill="rgb(210,16,53)" fg:x="1" fg:w="35"/><text x="2.1019%" y="286.50">last_token_probability (gpt2_probabilistic_model_wrapper.py:43)</text></g><g><title>_get_probability (gpt2_probabilistic_model_wrapper.py:91) (13 samples, 24.07%)</title><rect x="42.5926%" y="292" width="24.0741%" height="15" fill="rgb(235,124,12)" fg:x="23" fg:w="13"/><text x="42.8426%" y="302.50">_get_probability (gpt2_probabilistic_m..</text></g><g><title>_get_symbols_probabilities_dict (gpt2_probabilistic_model_wrapper.py:113) (13 samples, 24.07%)</title><rect x="42.5926%" y="308" width="24.0741%" height="15" fill="rgb(224,169,11)" fg:x="23" fg:w="13"/><text x="42.8426%" y="318.50">_get_symbols_probabilities_dict (gpt2_..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (13 samples, 24.07%)</title><rect x="42.5926%" y="324" width="24.0741%" height="15" fill="rgb(250,166,2)" fg:x="23" fg:w="13"/><text x="42.8426%" y="334.50">_call_impl (torch/nn/modules/module.py..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1315) (13 samples, 24.07%)</title><rect x="42.5926%" y="340" width="24.0741%" height="15" fill="rgb(242,216,29)" fg:x="23" fg:w="13"/><text x="42.8426%" y="350.50">forward (transformers/models/gpt2/mode..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (13 samples, 24.07%)</title><rect x="42.5926%" y="356" width="24.0741%" height="15" fill="rgb(230,116,27)" fg:x="23" fg:w="13"/><text x="42.8426%" y="366.50">_call_impl (torch/nn/modules/module.py..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1155) (1 samples, 1.85%)</title><rect x="64.8148%" y="372" width="1.8519%" height="15" fill="rgb(228,99,48)" fg:x="35" fg:w="1"/><text x="65.0648%" y="382.50">f..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (1 samples, 1.85%)</title><rect x="64.8148%" y="388" width="1.8519%" height="15" fill="rgb(253,11,6)" fg:x="35" fg:w="1"/><text x="65.0648%" y="398.50">_..</text></g><g><title>forward (torch/nn/modules/normalization.py:189) (1 samples, 1.85%)</title><rect x="64.8148%" y="404" width="1.8519%" height="15" fill="rgb(247,143,39)" fg:x="35" fg:w="1"/><text x="65.0648%" y="414.50">f..</text></g><g><title>layer_norm (torch/nn/functional.py:2347) (1 samples, 1.85%)</title><rect x="64.8148%" y="420" width="1.8519%" height="15" fill="rgb(236,97,10)" fg:x="35" fg:w="1"/><text x="65.0648%" y="430.50">l..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:312) (4 samples, 7.41%)</title><rect x="66.6667%" y="388" width="7.4074%" height="15" fill="rgb(233,208,19)" fg:x="36" fg:w="4"/><text x="66.9167%" y="398.50">forward (t..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (4 samples, 7.41%)</title><rect x="66.6667%" y="404" width="7.4074%" height="15" fill="rgb(216,164,2)" fg:x="36" fg:w="4"/><text x="66.9167%" y="414.50">_call_impl..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (4 samples, 7.41%)</title><rect x="66.6667%" y="420" width="7.4074%" height="15" fill="rgb(220,129,5)" fg:x="36" fg:w="4"/><text x="66.9167%" y="430.50">forward (t..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:614) (5 samples, 9.26%)</title><rect x="66.6667%" y="356" width="9.2593%" height="15" fill="rgb(242,17,10)" fg:x="36" fg:w="5"/><text x="66.9167%" y="366.50">forward (tran..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (5 samples, 9.26%)</title><rect x="66.6667%" y="372" width="9.2593%" height="15" fill="rgb(242,107,0)" fg:x="36" fg:w="5"/><text x="66.9167%" y="382.50">_call_impl (t..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:331) (1 samples, 1.85%)</title><rect x="74.0741%" y="388" width="1.8519%" height="15" fill="rgb(251,28,31)" fg:x="40" fg:w="1"/><text x="74.3241%" y="398.50">f..</text></g><g><title>_attn (transformers/models/gpt2/modeling_gpt2.py:208) (1 samples, 1.85%)</title><rect x="74.0741%" y="404" width="1.8519%" height="15" fill="rgb(233,223,10)" fg:x="40" fg:w="1"/><text x="74.3241%" y="414.50">_..</text></g><g><title>softmax (torch/nn/functional.py:1680) (1 samples, 1.85%)</title><rect x="74.0741%" y="420" width="1.8519%" height="15" fill="rgb(215,21,27)" fg:x="40" fg:w="1"/><text x="74.3241%" y="430.50">s..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:574) (2 samples, 3.70%)</title><rect x="75.9259%" y="388" width="3.7037%" height="15" fill="rgb(232,23,21)" fg:x="41" fg:w="2"/><text x="76.1759%" y="398.50">forw..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (2 samples, 3.70%)</title><rect x="75.9259%" y="404" width="3.7037%" height="15" fill="rgb(244,5,23)" fg:x="41" fg:w="2"/><text x="76.1759%" y="414.50">_cal..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (2 samples, 3.70%)</title><rect x="75.9259%" y="420" width="3.7037%" height="15" fill="rgb(226,81,46)" fg:x="41" fg:w="2"/><text x="76.1759%" y="430.50">forw..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:575) (8 samples, 14.81%)</title><rect x="79.6296%" y="388" width="14.8148%" height="15" fill="rgb(247,70,30)" fg:x="43" fg:w="8"/><text x="79.8796%" y="398.50">forward (transformers/m..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (8 samples, 14.81%)</title><rect x="79.6296%" y="404" width="14.8148%" height="15" fill="rgb(212,68,19)" fg:x="43" fg:w="8"/><text x="79.8796%" y="414.50">_call_impl (torch/nn/mo..</text></g><g><title>forward (transformers/activations.py:56) (8 samples, 14.81%)</title><rect x="79.6296%" y="420" width="14.8148%" height="15" fill="rgb(240,187,13)" fg:x="43" fg:w="8"/><text x="79.8796%" y="430.50">forward (transformers/a..</text></g><g><title>&lt;module&gt; (extraction_flame.py:112) (53 samples, 98.15%)</title><rect x="0.0000%" y="68" width="98.1481%" height="15" fill="rgb(223,113,26)" fg:x="0" fg:w="53"/><text x="0.2500%" y="78.50">&lt;module&gt; (extraction_flame.py:112)</text></g><g><title>run_learner_n_times (extraction_flame.py:106) (53 samples, 98.15%)</title><rect x="0.0000%" y="84" width="98.1481%" height="15" fill="rgb(206,192,2)" fg:x="0" fg:w="53"/><text x="0.2500%" y="94.50">run_learner_n_times (extraction_flame.py:106)</text></g><g><title>run_learner (extraction_flame.py:98) (53 samples, 98.15%)</title><rect x="0.0000%" y="100" width="98.1481%" height="15" fill="rgb(241,108,4)" fg:x="0" fg:w="53"/><text x="0.2500%" y="110.50">run_learner (extraction_flame.py:98)</text></g><g><title>learn (bounded_pdfa_quantization_n_ary_tree_learner.py:59) (17 samples, 31.48%)</title><rect x="66.6667%" y="116" width="31.4815%" height="15" fill="rgb(247,173,49)" fg:x="36" fg:w="17"/><text x="66.9167%" y="126.50">learn (bounded_pdfa_quantization_n_ary_tree_learner..</text></g><g><title>partial_hipothesis (bounded_pdfa_quantization_n_ary_tree_learner.py:82) (17 samples, 31.48%)</title><rect x="66.6667%" y="132" width="31.4815%" height="15" fill="rgb(224,114,35)" fg:x="36" fg:w="17"/><text x="66.9167%" y="142.50">partial_hipothesis (bounded_pdfa_quantization_n_ary..</text></g><g><title>cache_queries_for_building_hipothesis (pdfa_quantization_n_ary_tree_learner.py:276) (17 samples, 31.48%)</title><rect x="66.6667%" y="148" width="31.4815%" height="15" fill="rgb(245,159,27)" fg:x="36" fg:w="17"/><text x="66.9167%" y="158.50">cache_queries_for_building_hipothesis (pdfa_quantiz..</text></g><g><title>next_token_probabilities_batch (pymodelextractor/teachers/probabilistic_teacher.py:106) (17 samples, 31.48%)</title><rect x="66.6667%" y="164" width="31.4815%" height="15" fill="rgb(245,172,44)" fg:x="36" fg:w="17"/><text x="66.9167%" y="174.50">next_token_probabilities_batch (pymodelextractor/te..</text></g><g><title>get_last_token_weights_batch (synchronic_model_guided_language_model.py:74) (17 samples, 31.48%)</title><rect x="66.6667%" y="180" width="31.4815%" height="15" fill="rgb(236,23,11)" fg:x="36" fg:w="17"/><text x="66.9167%" y="190.50">get_last_token_weights_batch (synchronic_model_guid..</text></g><g><title>get_last_token_weights (synchronic_model_guided_language_model.py:126) (17 samples, 31.48%)</title><rect x="66.6667%" y="196" width="31.4815%" height="15" fill="rgb(205,117,38)" fg:x="36" fg:w="17"/><text x="66.9167%" y="206.50">get_last_token_weights (synchronic_model_guided_lan..</text></g><g><title>_raw_last_token_weights (synchronic_model_guided_language_model.py:102) (17 samples, 31.48%)</title><rect x="66.6667%" y="212" width="31.4815%" height="15" fill="rgb(237,72,25)" fg:x="36" fg:w="17"/><text x="66.9167%" y="222.50">_raw_last_token_weights (synchronic_model_guided_la..</text></g><g><title>get_last_token_weights (gpt2_probabilistic_model_wrapper.py:48) (17 samples, 31.48%)</title><rect x="66.6667%" y="228" width="31.4815%" height="15" fill="rgb(244,70,9)" fg:x="36" fg:w="17"/><text x="66.9167%" y="238.50">get_last_token_weights (gpt2_probabilistic_model_wr..</text></g><g><title>last_token_probability (gpt2_probabilistic_model_wrapper.py:43) (17 samples, 31.48%)</title><rect x="66.6667%" y="244" width="31.4815%" height="15" fill="rgb(217,125,39)" fg:x="36" fg:w="17"/><text x="66.9167%" y="254.50">last_token_probability (gpt2_probabilistic_model_wr..</text></g><g><title>_get_probability (gpt2_probabilistic_model_wrapper.py:87) (17 samples, 31.48%)</title><rect x="66.6667%" y="260" width="31.4815%" height="15" fill="rgb(235,36,10)" fg:x="36" fg:w="17"/><text x="66.9167%" y="270.50">_get_probability (gpt2_probabilistic_model_wrapper...</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (17 samples, 31.48%)</title><rect x="66.6667%" y="276" width="31.4815%" height="15" fill="rgb(251,123,47)" fg:x="36" fg:w="17"/><text x="66.9167%" y="286.50">_call_impl (torch/nn/modules/module.py:1102)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1315) (17 samples, 31.48%)</title><rect x="66.6667%" y="292" width="31.4815%" height="15" fill="rgb(221,13,13)" fg:x="36" fg:w="17"/><text x="66.9167%" y="302.50">forward (transformers/models/gpt2/modeling_gpt2.py:..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (17 samples, 31.48%)</title><rect x="66.6667%" y="308" width="31.4815%" height="15" fill="rgb(238,131,9)" fg:x="36" fg:w="17"/><text x="66.9167%" y="318.50">_call_impl (torch/nn/modules/module.py:1102)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:1129) (17 samples, 31.48%)</title><rect x="66.6667%" y="324" width="31.4815%" height="15" fill="rgb(211,50,8)" fg:x="36" fg:w="17"/><text x="66.9167%" y="334.50">forward (transformers/models/gpt2/modeling_gpt2.py:..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (17 samples, 31.48%)</title><rect x="66.6667%" y="340" width="31.4815%" height="15" fill="rgb(245,182,24)" fg:x="36" fg:w="17"/><text x="66.9167%" y="350.50">_call_impl (torch/nn/modules/module.py:1102)</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:651) (12 samples, 22.22%)</title><rect x="75.9259%" y="356" width="22.2222%" height="15" fill="rgb(242,14,37)" fg:x="41" fg:w="12"/><text x="76.1759%" y="366.50">forward (transformers/models/gpt2/m..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (12 samples, 22.22%)</title><rect x="75.9259%" y="372" width="22.2222%" height="15" fill="rgb(246,228,12)" fg:x="41" fg:w="12"/><text x="76.1759%" y="382.50">_call_impl (torch/nn/modules/module..</text></g><g><title>forward (transformers/models/gpt2/modeling_gpt2.py:576) (2 samples, 3.70%)</title><rect x="94.4444%" y="388" width="3.7037%" height="15" fill="rgb(213,55,15)" fg:x="51" fg:w="2"/><text x="94.6944%" y="398.50">forw..</text></g><g><title>_call_impl (torch/nn/modules/module.py:1102) (2 samples, 3.70%)</title><rect x="94.4444%" y="404" width="3.7037%" height="15" fill="rgb(209,9,3)" fg:x="51" fg:w="2"/><text x="94.6944%" y="414.50">_cal..</text></g><g><title>forward (transformers/pytorch_utils.py:105) (2 samples, 3.70%)</title><rect x="94.4444%" y="420" width="3.7037%" height="15" fill="rgb(230,59,30)" fg:x="51" fg:w="2"/><text x="94.6944%" y="430.50">forw..</text></g><g><title>all (54 samples, 100%)</title><rect x="0.0000%" y="52" width="100.0000%" height="15" fill="rgb(209,121,21)" fg:x="0" fg:w="54"/><text x="0.2500%" y="62.50"></text></g><g><title>&lt;module&gt; (extraction_flame.py:7) (1 samples, 1.85%)</title><rect x="98.1481%" y="68" width="1.8519%" height="15" fill="rgb(220,109,13)" fg:x="53" fg:w="1"/><text x="98.3981%" y="78.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (1 samples, 1.85%)</title><rect x="98.1481%" y="84" width="1.8519%" height="15" fill="rgb(232,18,1)" fg:x="53" fg:w="1"/><text x="98.3981%" y="94.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (1 samples, 1.85%)</title><rect x="98.1481%" y="100" width="1.8519%" height="15" fill="rgb(215,41,42)" fg:x="53" fg:w="1"/><text x="98.3981%" y="110.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (1 samples, 1.85%)</title><rect x="98.1481%" y="116" width="1.8519%" height="15" fill="rgb(224,123,36)" fg:x="53" fg:w="1"/><text x="98.3981%" y="126.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (1 samples, 1.85%)</title><rect x="98.1481%" y="132" width="1.8519%" height="15" fill="rgb(240,125,3)" fg:x="53" fg:w="1"/><text x="98.3981%" y="142.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (1 samples, 1.85%)</title><rect x="98.1481%" y="148" width="1.8519%" height="15" fill="rgb(205,98,50)" fg:x="53" fg:w="1"/><text x="98.3981%" y="158.50">_..</text></g><g><title>&lt;module&gt; (torch/__init__.py:29) (1 samples, 1.85%)</title><rect x="98.1481%" y="164" width="1.8519%" height="15" fill="rgb(205,185,37)" fg:x="53" fg:w="1"/><text x="98.3981%" y="174.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (1 samples, 1.85%)</title><rect x="98.1481%" y="180" width="1.8519%" height="15" fill="rgb(238,207,15)" fg:x="53" fg:w="1"/><text x="98.3981%" y="190.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (1 samples, 1.85%)</title><rect x="98.1481%" y="196" width="1.8519%" height="15" fill="rgb(213,199,42)" fg:x="53" fg:w="1"/><text x="98.3981%" y="206.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (1 samples, 1.85%)</title><rect x="98.1481%" y="212" width="1.8519%" height="15" fill="rgb(235,201,11)" fg:x="53" fg:w="1"/><text x="98.3981%" y="222.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (1 samples, 1.85%)</title><rect x="98.1481%" y="228" width="1.8519%" height="15" fill="rgb(207,46,11)" fg:x="53" fg:w="1"/><text x="98.3981%" y="238.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (1 samples, 1.85%)</title><rect x="98.1481%" y="244" width="1.8519%" height="15" fill="rgb(241,35,35)" fg:x="53" fg:w="1"/><text x="98.3981%" y="254.50">_..</text></g><g><title>&lt;module&gt; (torch/torch_version.py:3) (1 samples, 1.85%)</title><rect x="98.1481%" y="260" width="1.8519%" height="15" fill="rgb(243,32,47)" fg:x="53" fg:w="1"/><text x="98.3981%" y="270.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (1 samples, 1.85%)</title><rect x="98.1481%" y="276" width="1.8519%" height="15" fill="rgb(247,202,23)" fg:x="53" fg:w="1"/><text x="98.3981%" y="286.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (1 samples, 1.85%)</title><rect x="98.1481%" y="292" width="1.8519%" height="15" fill="rgb(219,102,11)" fg:x="53" fg:w="1"/><text x="98.3981%" y="302.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (1 samples, 1.85%)</title><rect x="98.1481%" y="308" width="1.8519%" height="15" fill="rgb(243,110,44)" fg:x="53" fg:w="1"/><text x="98.3981%" y="318.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (1 samples, 1.85%)</title><rect x="98.1481%" y="324" width="1.8519%" height="15" fill="rgb(222,74,54)" fg:x="53" fg:w="1"/><text x="98.3981%" y="334.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (1 samples, 1.85%)</title><rect x="98.1481%" y="340" width="1.8519%" height="15" fill="rgb(216,99,12)" fg:x="53" fg:w="1"/><text x="98.3981%" y="350.50">_..</text></g><g><title>&lt;module&gt; (pkg_resources/__init__.py:78) (1 samples, 1.85%)</title><rect x="98.1481%" y="356" width="1.8519%" height="15" fill="rgb(226,22,26)" fg:x="53" fg:w="1"/><text x="98.3981%" y="366.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (1 samples, 1.85%)</title><rect x="98.1481%" y="372" width="1.8519%" height="15" fill="rgb(217,163,10)" fg:x="53" fg:w="1"/><text x="98.3981%" y="382.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (1 samples, 1.85%)</title><rect x="98.1481%" y="388" width="1.8519%" height="15" fill="rgb(213,25,53)" fg:x="53" fg:w="1"/><text x="98.3981%" y="398.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (1 samples, 1.85%)</title><rect x="98.1481%" y="404" width="1.8519%" height="15" fill="rgb(252,105,26)" fg:x="53" fg:w="1"/><text x="98.3981%" y="414.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (1 samples, 1.85%)</title><rect x="98.1481%" y="420" width="1.8519%" height="15" fill="rgb(220,39,43)" fg:x="53" fg:w="1"/><text x="98.3981%" y="430.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (1 samples, 1.85%)</title><rect x="98.1481%" y="436" width="1.8519%" height="15" fill="rgb(229,68,48)" fg:x="53" fg:w="1"/><text x="98.3981%" y="446.50">_..</text></g><g><title>&lt;module&gt; (pkg_resources/_vendor/packaging/requirements.py:10) (1 samples, 1.85%)</title><rect x="98.1481%" y="452" width="1.8519%" height="15" fill="rgb(252,8,32)" fg:x="53" fg:w="1"/><text x="98.3981%" y="462.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (1 samples, 1.85%)</title><rect x="98.1481%" y="468" width="1.8519%" height="15" fill="rgb(223,20,43)" fg:x="53" fg:w="1"/><text x="98.3981%" y="478.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (1 samples, 1.85%)</title><rect x="98.1481%" y="484" width="1.8519%" height="15" fill="rgb(229,81,49)" fg:x="53" fg:w="1"/><text x="98.3981%" y="494.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:666) (1 samples, 1.85%)</title><rect x="98.1481%" y="500" width="1.8519%" height="15" fill="rgb(236,28,36)" fg:x="53" fg:w="1"/><text x="98.3981%" y="510.50">_..</text></g><g><title>module_from_spec (&lt;frozen importlib._bootstrap&gt;:565) (1 samples, 1.85%)</title><rect x="98.1481%" y="516" width="1.8519%" height="15" fill="rgb(249,185,26)" fg:x="53" fg:w="1"/><text x="98.3981%" y="526.50">m..</text></g><g><title>create_module (pkg_resources/extern/__init__.py:52) (1 samples, 1.85%)</title><rect x="98.1481%" y="532" width="1.8519%" height="15" fill="rgb(249,174,33)" fg:x="53" fg:w="1"/><text x="98.3981%" y="542.50">c..</text></g><g><title>load_module (pkg_resources/extern/__init__.py:37) (1 samples, 1.85%)</title><rect x="98.1481%" y="548" width="1.8519%" height="15" fill="rgb(233,201,37)" fg:x="53" fg:w="1"/><text x="98.3981%" y="558.50">l..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (1 samples, 1.85%)</title><rect x="98.1481%" y="564" width="1.8519%" height="15" fill="rgb(221,78,26)" fg:x="53" fg:w="1"/><text x="98.3981%" y="574.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (1 samples, 1.85%)</title><rect x="98.1481%" y="580" width="1.8519%" height="15" fill="rgb(250,127,30)" fg:x="53" fg:w="1"/><text x="98.3981%" y="590.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (1 samples, 1.85%)</title><rect x="98.1481%" y="596" width="1.8519%" height="15" fill="rgb(230,49,44)" fg:x="53" fg:w="1"/><text x="98.3981%" y="606.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (1 samples, 1.85%)</title><rect x="98.1481%" y="612" width="1.8519%" height="15" fill="rgb(229,67,23)" fg:x="53" fg:w="1"/><text x="98.3981%" y="622.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (1 samples, 1.85%)</title><rect x="98.1481%" y="628" width="1.8519%" height="15" fill="rgb(249,83,47)" fg:x="53" fg:w="1"/><text x="98.3981%" y="638.50">_..</text></g><g><title>&lt;module&gt; (pkg_resources/_vendor/pyparsing.py:89) (1 samples, 1.85%)</title><rect x="98.1481%" y="644" width="1.8519%" height="15" fill="rgb(215,43,3)" fg:x="53" fg:w="1"/><text x="98.3981%" y="654.50">&lt;..</text></g><g><title>_find_and_load (&lt;frozen importlib._bootstrap&gt;:1007) (1 samples, 1.85%)</title><rect x="98.1481%" y="660" width="1.8519%" height="15" fill="rgb(238,154,13)" fg:x="53" fg:w="1"/><text x="98.3981%" y="670.50">_..</text></g><g><title>_find_and_load_unlocked (&lt;frozen importlib._bootstrap&gt;:986) (1 samples, 1.85%)</title><rect x="98.1481%" y="676" width="1.8519%" height="15" fill="rgb(219,56,2)" fg:x="53" fg:w="1"/><text x="98.3981%" y="686.50">_..</text></g><g><title>_load_unlocked (&lt;frozen importlib._bootstrap&gt;:680) (1 samples, 1.85%)</title><rect x="98.1481%" y="692" width="1.8519%" height="15" fill="rgb(233,0,4)" fg:x="53" fg:w="1"/><text x="98.3981%" y="702.50">_..</text></g><g><title>exec_module (&lt;frozen importlib._bootstrap_external&gt;:850) (1 samples, 1.85%)</title><rect x="98.1481%" y="708" width="1.8519%" height="15" fill="rgb(235,30,7)" fg:x="53" fg:w="1"/><text x="98.3981%" y="718.50">e..</text></g><g><title>_call_with_frames_removed (&lt;frozen importlib._bootstrap&gt;:228) (1 samples, 1.85%)</title><rect x="98.1481%" y="724" width="1.8519%" height="15" fill="rgb(250,79,13)" fg:x="53" fg:w="1"/><text x="98.3981%" y="734.50">_..</text></g><g><title>&lt;module&gt; (pprint.py:103) (1 samples, 1.85%)</title><rect x="98.1481%" y="740" width="1.8519%" height="15" fill="rgb(211,146,34)" fg:x="53" fg:w="1"/><text x="98.3981%" y="750.50">&lt;..</text></g></svg></svg>